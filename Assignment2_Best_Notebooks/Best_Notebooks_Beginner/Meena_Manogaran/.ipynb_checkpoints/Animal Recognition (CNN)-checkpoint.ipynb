{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as  plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf  # Importing the TensorFlow Library\n",
    "from tensorflow import keras  # Import Keras from TensorFlow\n",
    "from tensorflow.keras import Sequential \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization,Conv2D,MaxPooling2D,Flatten\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import datetime\n",
    "\n",
    "%load_ext tensorboard\n",
    "import glob\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_labels=pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/animal_data/Training_set_animals.csv\")\n",
    "testing_labels=pd.read_csv(\"https://raw.githubusercontent.com/dphi-official/Datasets/master/animal_data/Testing_set_animals.csv\",header=None)\n",
    "testing_labels.columns=['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pecora    600\n",
       "mucca     600\n",
       "Name: animal_type, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_labels['animal_type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images = []\n",
    "for img in glob.glob(r'C:\\Users\\Meena\\Desktop\\Dphi\\bootcamp\\Assignment_2\\train\\train_beg\\*.jpg'):\n",
    "    n= cv2.imread(img)\n",
    "    training_images.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_images = []\n",
    "for img in glob.glob(r'C:\\Users\\Meena\\Desktop\\Dphi\\bootcamp\\Assignment_2\\test\\test_beg\\*.jpg'):\n",
    "    n= cv2.imread(img)\n",
    "    testing_images.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels i.e.  1200 matches the number of filenames i.e.  1200\n"
     ]
    }
   ],
   "source": [
    "if len(training_labels) == len(training_images):\n",
    "    print('Number of labels i.e. ', len(training_labels), 'matches the number of filenames i.e. ', len(training_images))\n",
    "else:\n",
    "    print('Number of labels doesnot matches the number of filenames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels i.e.  400 matches the number of filenames i.e.  400\n"
     ]
    }
   ],
   "source": [
    "if len(testing_labels) == len(testing_images):\n",
    "    print('Number of labels i.e. ', len(testing_labels), 'matches the number of filenames i.e. ', len(testing_images))\n",
    "else:\n",
    "    print('Number of labels doesnot matches the number of filenames')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testing_images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1=r\"C:\\Users\\Meena\\Desktop\\Dphi\\bootcamp\\Assignment_2\\train\\train_beg/\"\n",
    "\n",
    "    \n",
    "images = [[fname, path1+ fname[:-4] + '.jpg'] for fname in training_labels['filename']]\n",
    "train_df = pd.DataFrame(images)\n",
    "train_df.columns = ['filename', 'file']\n",
    "train_df['labels']=training_labels['animal_type']\n",
    "\n",
    "def mappp(x):\n",
    "    if x==\"mucca\":\n",
    "        return 0\n",
    "    else: return 1\n",
    "    \n",
    "train_df['labels_num']=train_df['labels'].map(mappp)\n",
    "y_train=np.array(train_df['labels_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train=[]\n",
    "for img in train_df['file']:\n",
    "    img=cv2.imread(img)\n",
    "    img = cv2.resize(img, (64,64))\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    images_train.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train=np.array(images_train)\n",
    "plt.matshow(images_train[9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_rows, num_cols = 2,3\n",
    "f, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n",
    "                     gridspec_kw={'wspace':0.15, 'hspace':0.15}, \n",
    "                     squeeze=True)\n",
    "\n",
    "for r in range(num_rows):\n",
    "    for c in range(num_cols):\n",
    "      \n",
    "        image_index = r*650 + c\n",
    "        ax[r,c].axis(\"off\")\n",
    "        ax[r,c].imshow(images_train[image_index], cmap='gray')\n",
    "        ax[r,c].set_title(train_df['labels'][image_index])\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path2=r\"C:\\Users\\Meena\\Desktop\\Dphi\\bootcamp\\Assignment_2\\test\\test_beg/\"\n",
    "\n",
    "images = [[fname, path2+ fname[:-4] + '.jpg'] for fname in testing_labels['filename']]\n",
    "test_df = pd.DataFrame(images)\n",
    "test_df.columns = ['filename', 'file']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test=[]\n",
    "for img in test_df['file']:\n",
    "    img=cv2.imread(img)\n",
    "    #img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.resize(img, (64,64))\n",
    "    images_test.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test=np.array(images_test)\n",
    "plt.matshow(images_test[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_cols = 2,3\n",
    "f, ax = plt.subplots(num_rows, num_cols, figsize=(12,5),\n",
    "                     gridspec_kw={'wspace':0.15, 'hspace':0.15}, \n",
    "                     squeeze=True)\n",
    "\n",
    "for r in range(num_rows):\n",
    "    for c in range(num_cols):\n",
    "      \n",
    "        image_index = r*200 + c\n",
    "        ax[r,c].axis(\"off\")\n",
    "        ax[r,c].imshow(images_test[image_index], cmap='gray')\n",
    "        \n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 64, 64, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 64, 64, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification=['mucca','pecora']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.array(train_df['labels_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SHAPE = (64,64,3)\n",
    "\n",
    "# define sequential model\n",
    "model = tf.keras.models.Sequential()\n",
    "# define conv-pool layers - set 1\n",
    "model.add(tf.keras.layers.Conv2D(filters=70, kernel_size=(2, 2), strides=(1, 1), \n",
    "                                activation='relu', padding='valid', input_shape=INPUT_SHAPE))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(3, 3)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# add flatten layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# add dense layers with some dropout\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(rate=0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.losses import CategoricalHinge\n",
    "model.compile(optimizer='Adam', \n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, validate_df = train_test_split(train_df, test_size=0.20, random_state=42)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "validate_df = validate_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train = train_df.shape[0]\n",
    "total_validate = validate_df.shape[0]\n",
    "batch_size=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    rescale=1./255,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.3,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 960 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_dataframe(train_df,r'C:\\Users\\Meena\\Desktop\\Dphi\\bootcamp\\Assignment_2\\train\\train_beg/',\n",
    "                                             x_col='filename',y_col='labels',class_mode='binary',\n",
    "                                   batch_size=32, target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 240 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_dataframe(\n",
    "    validate_df, \n",
    "    r'C:\\Users\\Meena\\Desktop\\Dphi\\bootcamp\\Assignment_2\\train\\train_beg/',\n",
    "                                             x_col='filename',y_col='labels',class_mode='binary',\n",
    "                                   batch_size=5, target_size=(64,64))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
    "#    epochs=20, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(0, 15):\n",
    "    plt.subplot(5, 3, i+1)\n",
    "    for X_batch, Y_batch in train_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "example_df = train_df.sample(n=2).reset_index(drop=True)\n",
    "example_df.head()\n",
    "example_generator = train_datagen.flow_from_dataframe(\n",
    "    example_df, \n",
    "    r'C:\\Users\\Meena\\Desktop\\Dphi\\bootcamp\\Assignment_2\\train\\train_beg/', \n",
    "    x_col='filename',\n",
    "    y_col='labels',\n",
    "    target_size=(64,64),\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(0, 15):\n",
    "    plt.subplot(5, 3, i+1)\n",
    "    for X_batch, Y_batch in example_generator:\n",
    "        image = X_batch[0]\n",
    "        plt.imshow(image)\n",
    "        break\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 5s 170ms/step - loss: 0.7214 - accuracy: 0.5115 - val_loss: 0.6664 - val_accuracy: 0.6000\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 5s 154ms/step - loss: 0.6857 - accuracy: 0.5479 - val_loss: 0.6700 - val_accuracy: 0.5714\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 5s 155ms/step - loss: 0.6659 - accuracy: 0.6031 - val_loss: 0.6434 - val_accuracy: 0.6857\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 5s 152ms/step - loss: 0.6482 - accuracy: 0.6177 - val_loss: 0.5740 - val_accuracy: 0.7714\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 5s 160ms/step - loss: 0.6443 - accuracy: 0.6313 - val_loss: 0.5769 - val_accuracy: 0.6571\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 5s 163ms/step - loss: 0.6279 - accuracy: 0.6385 - val_loss: 0.5758 - val_accuracy: 0.6571\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 5s 155ms/step - loss: 0.6199 - accuracy: 0.6635 - val_loss: 0.5180 - val_accuracy: 0.8286\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 5s 154ms/step - loss: 0.6232 - accuracy: 0.6604 - val_loss: 0.6150 - val_accuracy: 0.6286\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 5s 164ms/step - loss: 0.6149 - accuracy: 0.6562 - val_loss: 0.5998 - val_accuracy: 0.6857\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 5s 151ms/step - loss: 0.6140 - accuracy: 0.6792 - val_loss: 0.4716 - val_accuracy: 0.8286\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 5s 161ms/step - loss: 0.6024 - accuracy: 0.7010 - val_loss: 0.5666 - val_accuracy: 0.6286\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 5s 162ms/step - loss: 0.6098 - accuracy: 0.6760 - val_loss: 0.6136 - val_accuracy: 0.6286\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.6917Restoring model weights from the end of the best epoch.\n",
      "30/30 [==============================] - 5s 153ms/step - loss: 0.5974 - accuracy: 0.6917 - val_loss: 0.5873 - val_accuracy: 0.8000\n",
      "Epoch 00013: early stopping\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "es_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, \n",
    "                                               restore_best_weights=True,\n",
    "                                               verbose=1)\n",
    "history = model.fit(\n",
    "    train_generator, \n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=total_validate//batch_size,\n",
    "    steps_per_epoch=total_train//batch_size,\n",
    "    callbacks=[es_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 63, 63, 70)        910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 21, 21, 70)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30870)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                987872    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 989,871\n",
      "Trainable params: 989,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_gen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_gen.flow_from_dataframe(\n",
    "    test_df, \n",
    "    r'C:\\Users\\Meena\\Desktop\\Dphi\\bootcamp\\Assignment_2\\test\\test_beg/', \n",
    "    x_col='filename',\n",
    "    y_col=None,\n",
    "    class_mode=None,\n",
    "    target_size=(64,64),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=model.predict(test_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=np.round(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final=[]\n",
    "# for i in range(0,len(images_test)):\n",
    "#     final.append(np.argmax(y_predict[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pecora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pecora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mucca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mucca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pecora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>pecora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>pecora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>mucca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>pecora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>pecora</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0    pecora\n",
       "1    pecora\n",
       "2     mucca\n",
       "3     mucca\n",
       "4    pecora\n",
       "..      ...\n",
       "395  pecora\n",
       "396  pecora\n",
       "397   mucca\n",
       "398  pecora\n",
       "399  pecora\n",
       "\n",
       "[400 rows x 1 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g=pd.DataFrame(n)\n",
    "g[0]=g[0].replace({1.0:'pecora',0.0:'mucca'})\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = g #target is nothing but the final predictions of your model on input features of your new unseen test data\n",
    "#res.index = test.index # its important for comparison. Here \"test_new\" is your new test dataset\n",
    "res.columns = [\"prediction\"]\n",
    "\n",
    "\n",
    "res.to_csv(\"anim1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\MachineLearning\\anaconda\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: saved_model/my_model_cnn1\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('saved_model/my_model_cnn1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
